# 模型配置
model:
  name: "/data/staryea/aigc_model/Qwen2.5-3B-Instruct"
  max_seq_length: 2048
  lora_rank: 64
  load_in_4bit: true
  fast_inference: false
  gpu_memory_utilization: 0.2

# 训练配置
training:
  learning_rate: 3.0e-6
  batch_size: 1
  gradient_accumulation_steps: 4
  max_steps: 500
  save_steps: 500
  warmup_ratio: 0.03
  weight_decay: 0.1
  max_grad_norm: 0.1
  seed: 42
  logging_steps: 1

# 数据配置
data:
  # 方式1: 本地数据集
  dataset_type: "local"  # 或 "huggingface"
  dataset_name: "/data/staryea/gsm8k/socratic"
  dataset_format: "json"  # 本地数据集格式：json, csv, parquet 等
  dataset_config: "default"
  split: "train"
  
  # 或者方式2: Hugging Face数据集
  # dataset_type: "huggingface"
  # dataset_name: "gsm8k"
  # dataset_config: "main"
  # split: "train"
  
  system_prompt: |
    按照以下格式进行数学问题的细致推理和解答：
    在Think中要理解问题要求并列出已知条件尝试设计解题策略开始逐步计算过程并考虑验证结果
    在answer中请详细验证推理结果答案是否准确并且补充说明解法的适用条件或限制查看可能存在的其他解法或变化思考相关的数学概念和注意事项并尝试使用MarkDown格式输出。
    请使用中文并且使用以下格式进行输出：
    <Think>
    ...
    </Think>

    <answer>
    ...
    </answer>
  output_format: |
    <Think>
    {Think}
    </Think>
    <answer>
    {answer}
    </answer>

# wandb配置
wandb:
  project: "logic-rl"
  enabled: true


# 输出配置
output:
  dir: "outputs"
  save_model: true
  model_name: "grpo_saved_lora"


# 建议添加日志配置
logging:
  level: "INFO"
  save_path: "logs"

# 测试配置
test:
  enabled: false
  temperature: 0.8
  top_p: 0.95
  max_tokens: 2048 
